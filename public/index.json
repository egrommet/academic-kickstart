[{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m a Senior Lecturer in Data Journalism at Cardiff University\u0026rsquo;s School of Journalism, Media and Culture.\nI\u0026rsquo;m the co-director of the MSc in Computational and Data Journalism and a co-founder of the European Data and Computational Journalism Conference. My interests include data journalism, journalism and software development, social media and production journalism.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://egrommet.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"I\u0026rsquo;m a Senior Lecturer in Data Journalism at Cardiff University\u0026rsquo;s School of Journalism, Media and Culture.\nI\u0026rsquo;m the co-director of the MSc in Computational and Data Journalism and a co-founder of the European Data and Computational Journalism Conference. My interests include data journalism, journalism and software development, social media and production journalism.","tags":null,"title":"Glyn Mottershead","type":"author"},{"authors":["Glyn Mottershead"],"categories":null,"content":"","date":1554381000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554381000,"objectID":"74e6a49cd95b6782e0b5665eb8dd9b8d","permalink":"https://egrommet.github.io/talk/digital-city/","publishdate":"2019-03-07T00:00:00Z","relpermalink":"/talk/digital-city/","section":"talk","summary":"Data, algorithms, chatbots and computational journalism impacting on newsrooms, are you ready?","tags":[],"title":"Data and Computational Journalism","type":"talk"},{"authors":null,"categories":["R","Data Visualisation","Mapping"],"content":" Mapping in R - using ggplot2, part two In the previous tutorial we looked at getting data from web APIs in JSON and GeoJSON formats to create a simple map.\nThis time we\u0026rsquo;ll be adapting code from Timo Grossenbacher to make our map more attractive.\nGetting started We need to reload the data again, so we\u0026rsquo;re going to get a different number of signatures than last time.\nI\u0026rsquo;m going to run this in one block and assume you can follow along, if not go back to the previous post.\n# Load the mapping file library(geojsonio)  ## ## Attaching package: 'geojsonio'  ## The following object is masked from 'package:base': ## ## pretty  url \u0026lt;- \u0026quot;https://opendata.arcgis.com/datasets/5ce27b980ffb43c39b012c2ebeab92c0_2.geojson\u0026quot; uk_map \u0026lt;- geojson_read(url, what = \u0026quot;sp\u0026quot;) # Convert to a ggplot-friendly format library(ggplot2) fort_uk_map \u0026lt;- fortify(uk_map, region = \u0026quot;pcon17cd\u0026quot;) # Get the data from the petition site library(jsonlite)  ## ## Attaching package: 'jsonlite'  ## The following object is masked from 'package:geojsonio': ## ## validate  json_data \u0026lt;- fromJSON(\u0026quot;https://petition.parliament.uk/petitions/241584.json\u0026quot;, flatten = FALSE) # Turn it into a datafram sign_data \u0026lt;- json_data$data$attributes$signatures_by_constituency # Store the mumber of signatures for later total_sig \u0026lt;- sum(sign_data$signature_count) # Join the two datasets together library(dplyr)  ## ## Attaching package: 'dplyr'  ## The following objects are masked from 'package:stats': ## ## filter, lag  ## The following objects are masked from 'package:base': ## ## intersect, setdiff, setequal, union  full_uk_map \u0026lt;- left_join(fort_uk_map, sign_data, by = c(\u0026quot;id\u0026quot; = \u0026quot;ons_code\u0026quot;))  One of the things I really liked about Timo\u0026rsquo;s post is that he divided the vote count into bands (buckets) to help make it easier to see what is going on. I like the previous map but it isn\u0026rsquo;t massively easy to read. I\u0026rsquo;m not going to go into a lot on data viz theory here, but I strongly recommend you have a look at the work of Alberto Cairo.\nBlue is the colour What I didn\u0026rsquo;t explain last time is that the default colour of our last map was blue. This time I want it to be intentional and echo the blue background of the European flag, so the deeper blues signify more Europhile constituencies.\nThere is a problem with maps - they often just show where the population is biggest, we could go int detail about constituencies to scale it more effectively but it gives us an interesting starting point. \u0026ldquo;The Office for National Statistics gives the median total parliamentary electorate across constituencies of about 72,400 in England, 69,000 in Scotland, 66,800 in Northern Ireland and 56,800 in Wales.\u0026rdquo; Source\nI like to use colorbrewer when I\u0026rsquo;m working with maps, you can have a much more nuanced colour range than using R\u0026rsquo;s default (yes it can be done in R default, but I\u0026rsquo;ve personally found it to be more fiddly). And, it is also a function that is built into ggplot2 scale_fill_brewer() - which will make our life easier.\nBut this gives us a bit of a problem as our colorbrewer function call only allows us nine shades of blue. If we tried using it as it stands we\u0026rsquo;d throw an error message similar to this 1: In brewer.pal(n, pal): n too large, allowed maximum for palette\u0026hellip;.\nSo, we\u0026rsquo;ll chop our vote range into blocks as per Timo\u0026rsquo;s post, create labels that allow us to explain the blocks, colour it according to our new range and then add a them to make it look good. His post goes into a lot more detail (obviously!).\nThere\u0026rsquo;s whole in my bucket We\u0026rsquo;ll start off by declaring how many colour buckets we want to use, we\u0026rsquo;ll store it as a variable.\nno_classes \u0026lt;- 9  The next thing to do is then chop our voter range into sections (we want 9), we\u0026rsquo;ll be using quantiles() to do that. We\u0026rsquo;ll give our function the numbers in the signature count column of our full_uk_map. The probs argument takes the number of classes and then calculates the bands for us.\nquantiles \u0026lt;- quantile(full_uk_map$signature_count, probs = seq(0, 1, length.out = no_classes + 1))  Next we create an empty vector for the labels for our map legend, essentially an empty box to store the next stage in.\nThe second part uses a for loop to run through our number range and create the labels. We\u0026rsquo;ll round to the nearest whole number (as you can\u0026rsquo;t get part of a vote, but our quantiles calculation would give that).\nlabels \u0026lt;- c() for(band in 1:length(quantiles)){ labels \u0026lt;- c(labels, paste0(round(quantiles[band]), \u0026quot; – \u0026quot;, round(quantiles[band + 1]))) } labels  ## [1] \u0026quot;1965 – 3874\u0026quot; \u0026quot;3874 – 4579\u0026quot; \u0026quot;4579 – 5302\u0026quot; \u0026quot;5302 – 6478\u0026quot; ## [5] \u0026quot;6478 – 7557\u0026quot; \u0026quot;7557 – 9025\u0026quot; \u0026quot;9025 – 9642\u0026quot; \u0026quot;9642 – 11102\u0026quot; ## [9] \u0026quot;11102 – 36917\u0026quot; \u0026quot;36917 – NA\u0026quot;  And we\u0026rsquo;ve got a problem - the code gives us a final band that looks like \u0026ldquo;36901 - NA\u0026rdquo;, anything over our maximum. We can easily get rid of that as obviously we are limited at the maximum.\nlabels \u0026lt;- labels[1:length(labels)-1] labels  ## [1] \u0026quot;1965 – 3874\u0026quot; \u0026quot;3874 – 4579\u0026quot; \u0026quot;4579 – 5302\u0026quot; \u0026quot;5302 – 6478\u0026quot; ## [5] \u0026quot;6478 – 7557\u0026quot; \u0026quot;7557 – 9025\u0026quot; \u0026quot;9025 – 9642\u0026quot; \u0026quot;9642 – 11102\u0026quot; ## [9] \u0026quot;11102 – 36917\u0026quot;  Next, we need to add our new number range to the map. We\u0026rsquo;ll do this with the cut() function, to turn our number range into a factor.\nfull_uk_map$quantiles \u0026lt;- cut(full_uk_map$signature_count, breaks = quantiles, labels = labels, include.lowest = T)  Now we can make our map. This time we\u0026rsquo;ll use our new quantiles column as the fill. We\u0026rsquo;ll use scale_fill_brewer() to give us our \u0026lsquo;European\u0026rsquo; blue colour range and put the legend at the bottom. we\u0026rsquo;ll use the labs() element of ggplot2 to give us a headline, catptions and attribution.\nby_quantile \u0026lt;- ggplot() + geom_polygon(data = full_uk_map, aes(x = long, y = lat, group = group, fill = quantiles)) + geom_path(color = \u0026quot;black\u0026quot;, size = 0.1) + scale_fill_brewer(type = \u0026quot;qual\u0026quot;, palette = \u0026quot;Blues\u0026quot;, guide = \u0026quot;legend\u0026quot;, name = \u0026quot;Signature\\nCount\u0026quot;, labels = labels) + # I've commmented out theme_void() so you can see what the built-in themes do # theme_void() + theme(legend.position = \u0026quot;bottom\u0026quot;) + labs(x = NULL, y = NULL, title = \u0026quot;Signatories of the Revoke Article 50 Petition\u0026quot;, subtitle = \u0026quot;Let's investigate where the signatures come from\u0026quot;, caption = \u0026quot;Geometries: ONS Open Geography Portal; Data: UK Parliament and Government\u0026quot;) by_quantile  The next thing we can try is adding a theme. I\u0026rsquo;m just going to use the one from Timo\u0026rsquo;s post but change the font family. It is being stored as a function, so we can call it easily.\ntheme_map \u0026lt;- function(...) { theme_minimal() + theme( text = element_text(family = \u0026quot;Helvetica\u0026quot;, color = \u0026quot;#22211d\u0026quot;), axis.line = element_blank(), axis.text.x = element_blank(), axis.text.y = element_blank(), axis.ticks = element_blank(), axis.title.x = element_blank(), axis.title.y = element_blank(), # panel.grid.minor = element_line(color = \u0026quot;#ebebe5\u0026quot;, size = 0.2), panel.grid.major = element_line(color = \u0026quot;#ebebe5\u0026quot;, size = 0.2), panel.grid.minor = element_blank(), plot.background = element_rect(fill = \u0026quot;#f5f5f2\u0026quot;, color = NA), panel.background = element_rect(fill = \u0026quot;#f5f5f2\u0026quot;, color = NA), legend.background = element_rect(fill = \u0026quot;#f5f5f2\u0026quot;, color = NA), panel.border = element_blank(), ... ) }  And this time we\u0026rsquo;ll use the theme as part of our final version. We\u0026rsquo;re also going to pull a little trick in the title - remember we saved the number of votes in total earlier on as total_sig? We can use the paste0() function to put the number in the text, with the added advantage that the number will automatically update from the API when we run all the code again.\nby_quantile2 \u0026lt;- ggplot() + geom_polygon(data = full_uk_map, aes(x = long, y = lat, group = group, fill = quantiles)) + geom_path(color = \u0026quot;black\u0026quot;, size = 0.1) + scale_fill_brewer(type = \u0026quot;qual\u0026quot;, palette = \u0026quot;Blues\u0026quot;, guide = \u0026quot;legend\u0026quot;, name = \u0026quot;Signature\\nCount\u0026quot;, labels = labels) + theme_void() + coord_equal() + theme_map() + theme(legend.position = \u0026quot;bottom\u0026quot;) + labs(x = NULL, y = NULL, title = \u0026quot;Signatories of the Revoke Article 50 Petition\u0026quot;, subtitle = paste0(\u0026quot;Let's investigate where the \u0026quot;, format(total_sig, big.mark = \u0026quot;,\u0026quot;), \u0026quot; signatures come from\u0026quot;), caption = \u0026quot;Geometries: ONS Open Geography Portal; Data: UK Parliament and Government\u0026quot;) by_quantile2  At some stage I\u0026rsquo;m going to play around with the background to declare the plot size (I\u0026rsquo;m guessing that is why it is breaking the bounds here - but the version at the top is exported from the code run in RStudio), I\u0026rsquo;ll post when I do but for now I\u0026rsquo;m going to stop here.\nRemember, Timo goes on much further to make a really beatiful map.\n","date":1554076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554076800,"objectID":"eada26b3a8496f1d533e96d8d242253d","permalink":"https://egrommet.github.io/tutorial/mapping-the-article-50-petition-in-r-and-ggplot-part-2/","publishdate":"2019-04-01T00:00:00Z","relpermalink":"/tutorial/mapping-the-article-50-petition-in-r-and-ggplot-part-2/","section":"tutorial","summary":"Mapping in R - using ggplot2, part two In the previous tutorial we looked at getting data from web APIs in JSON and GeoJSON formats to create a simple map.\nThis time we\u0026rsquo;ll be adapting code from Timo Grossenbacher to make our map more attractive.\nGetting started We need to reload the data again, so we\u0026rsquo;re going to get a different number of signatures than last time.\nI\u0026rsquo;m going to run this in one block and assume you can follow along, if not go back to the previous post.","tags":["ggplot2","json","map"],"title":"Mapping the article 50 petition in R and ggplot - part 2","type":"tutorial"},{"authors":null,"categories":["R","Mapping","Data Visualisation"],"content":" Mapping in R - using ggplot2 The Revoke Article 50 petition got my colleague and all-round codemeister Dr Martin Chorley and I talking.\nWe started thinking about ways that we could see what the patterns for people signing were like.\nIt was well into the millions when I started playing with ways of visualising where people who voted were located. The site can map all of the signatures (5,962,824 at the time of writing), but it also has an option to get the data in a machine-friendly json format.\nAccording to the site:\nThe data shows the number of people who have signed the petition by country as well as in the constituency of each Member of Parliament. This data is available for all petitions on the site. It is not a list of people who have signed the petition. The only name that is shared on the site is that of the petition creator.\nGetting started You\u0026rsquo;ll need to install the following packages: install.packages(c(\u0026quot;geojsonio\u0026quot;, \u0026quot;ggplot2\u0026quot;, \u0026quot;dplyr\u0026quot;, \u0026quot;jsonlite\u0026quot;))\nGetting the map shapes We\u0026rsquo;re going to use geojsonio first to get a mapping file from the ONS Open Geography Portal. It has a great respository of mapping files. We\u0026rsquo;ll be using the parliamentary wards file. Go to the site and use the menu bar to: Boundaries \u0026gt; Electoral Boundaries \u0026gt; Westminster Parliamentary Constituencies \u0026gt; 2017 Boundaries\nYou can download the file in a variety of formats, but we\u0026rsquo;re going to use the API to import it directly in GeoJSON format.\nNB At the time of writing there appeared to be a glitch in the site, I actually found the right map home page via a search engine.\nFirst we use the library() function to call geojsonio to handle the file, we\u0026rsquo;ll store the URL as a variable and then read it in to our working environment. The \u0026lsquo;what\u0026rsquo; argument uses \u0026ldquo;sp\u0026rdquo; - spacial class for a mapping file.\nlibrary(geojsonio)  ## ## Attaching package: 'geojsonio'  ## The following object is masked from 'package:base': ## ## pretty  url \u0026lt;- \u0026quot;https://opendata.arcgis.com/datasets/5ce27b980ffb43c39b012c2ebeab92c0_2.geojson\u0026quot; uk_map \u0026lt;- geojson_read(url, what = \u0026quot;sp\u0026quot;)  We then need to turn it from the form it is in to something we can map more easily in ggplot2, so we\u0026rsquo;ll call the library here and use the fortify() function.\nBy having a look in side the uk_map dataframe we can see our code names for the constituencies are stored in pcon17cd, so we\u0026rsquo;ll add that as our region.\nlibrary(ggplot2) fort_uk_map \u0026lt;- fortify(uk_map, region = \u0026quot;pcon17cd\u0026quot;)  Getting the data for our map We\u0026rsquo;re now going to read in the data from the Parliament Petitions site. We\u0026rsquo;ll use jsonlite to do that.\nlibrary(jsonlite)  ## ## Attaching package: 'jsonlite'  ## The following object is masked from 'package:geojsonio': ## ## validate  json_data \u0026lt;- fromJSON(\u0026quot;https://petition.parliament.uk/petitions/241584.json\u0026quot;, flatten = FALSE)  The next thing we need to do is get the data out of the json file we just imported. If you click on the json_data object in the Environment pane, you\u0026rsquo;ll see it is a list of two - double click to open it up and we cab view the file. Inside the json-data structure we can see data has a list of three objects inside it, opening that shows us attributes is where the intersting things are happening.\nThere\u0026rsquo;s a lot going on but there are two things that interest me for mapping - signatures_by_constituency and signatures_by_country (this second one is for a later date).\nOpening the signatures_by_country list shows it has the following elements name, ons_code, mp, signature_count for each of the 650 constituencies in the file. The ons_code will come in useful later when we want to merge our map and data together.\nWe can move through the levels of our json_data object in this fashion name$parent_element$child_element.\nSo in our case: ign_data \u0026lt;- json_data$data$attributes$signatures_by_constituency\nWe\u0026rsquo;ll store that in a dataframe and while we\u0026rsquo;re at it we\u0026rsquo;ll calculate how many signatures there were at the time of running the code, I\u0026rsquo;ll do this as a dataframe as it will be useful in the second tutorial.\nsign_data \u0026lt;- json_data$data$attributes$signatures_by_constituency total_sig \u0026lt;- sum(sign_data$signature_count) total_sig  ## [1] 5677813  Joing the data sets This is where dplyr comes into its own as a data-wrangling toolkit. We\u0026rsquo;ll call the library and then use a left_join() to merge them together into a new dataframe called full_uk_map. There\u0026rsquo;s an explanation of join types on the tidyverse site.\nTo do the join we have to tell the function where our common columns are in the \u0026lsquo;by\u0026rsquo; element \u0026ndash; left_join(dataset1, dataset2, by = c(\u0026quot;a_column\u0026quot; = \u0026quot;the_equivalent_column\u0026quot;))\nlibrary(dplyr)  ## ## Attaching package: 'dplyr'  ## The following objects are masked from 'package:stats': ## ## filter, lag  ## The following objects are masked from 'package:base': ## ## intersect, setdiff, setequal, union  full_uk_map \u0026lt;- left_join(fort_uk_map, sign_data, by = c(\u0026quot;id\u0026quot; = \u0026quot;ons_code\u0026quot;))  Basic ggplot2 map We\u0026rsquo;ll start off with a simple map that shows which constituency people are signing from, so we need to load ggplot2 as a function. I\u0026rsquo;ll break down the structure below for what we are doing here.\n# Call ggplot here as a function and use the '+' symbol to denote 'and then' ggplot() + # We'll use geom_polygon() and tell it where the data is, what our aesthetics are and what to fill how to create it as a choropleth map. geom_polygon(data = full_uk_map, aes(x = long, y = lat, group = group, fill = signature_count)) + # We'll put a white stroke on the constituency boundaries geom_path(color = \u0026quot;white\u0026quot;) + # Get rid of the background theme_void() + # And finally let's use coord_equal to ensure the x and y scales are the same. coord_equal()  Figure 1 A simple choropleth map.\n Next steps I\u0026rsquo;ve also been playing with a great post from Timo Grossenbaher on how to make beatiful thematic maps with ggplot2 to create something a bit more effective.\nNow pop along to stage two of this tutorial which goes further and looks at making things more interesting.\nMore analysis Andy Dickinson from Manchester Met has done a Pandas (Python) look at the article 50 and knife crime petitions.\n","date":1553817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553817600,"objectID":"ebe7d49627ddf2e04464983e286bdaf5","permalink":"https://egrommet.github.io/tutorial/mapping-the-article-50-petition-in-r-and-ggplot/","publishdate":"2019-03-29T00:00:00Z","relpermalink":"/tutorial/mapping-the-article-50-petition-in-r-and-ggplot/","section":"tutorial","summary":"Mapping in R - using ggplot2 The Revoke Article 50 petition got my colleague and all-round codemeister Dr Martin Chorley and I talking.\nWe started thinking about ways that we could see what the patterns for people signing were like.\nIt was well into the millions when I started playing with ways of visualising where people who voted were located. The site can map all of the signatures (5,962,824 at the time of writing), but it also has an option to get the data in a machine-friendly json format.","tags":["json","map","ggplot2"],"title":"Mapping the article 50 petition in R and ggplot","type":"tutorial"},{"authors":["Glyn Mottershead","Martin Chorley"],"categories":null,"content":"","date":1543622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543622400,"objectID":"2d93fe7431ea20f085cd80d300c6ac11","permalink":"https://egrommet.github.io/publication/nieman-predictions-2019/","publishdate":"2018-12-01T00:00:00Z","relpermalink":"/publication/nieman-predictions-2019/","section":"publication","summary":"Every time a free tool goes freemium or a platform closes because it can’t make money, we’ve got an issue. What’s going to happen to the stories that tool feeds?","tags":["Journalism","Data Journalism","News Writing","Feature Writing","Journalism Education"],"title":"When a tech company pulls the plug on your story","type":"publication"},{"authors":["Martin Chorley","Glyn Mottershead"],"categories":null,"content":"","date":1535756400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535756400,"objectID":"79f483fecb548075e055a280902e02cf","permalink":"https://egrommet.github.io/publication/are-you-talking-book-chapter/","publishdate":"2018-09-01T00:00:00+01:00","relpermalink":"/publication/are-you-talking-book-chapter/","section":"publication","summary":"This preliminary research aims to show how computational analysis allows us to investigate the means by which news stories are spread.","tags":["Twitter","Data Analysis","Social Media","Journalism Studies"],"title":"Are You Talking To Me?: An Analysis of Journalism Conversation on Social Media","type":"publication"},{"authors":["Jonathan Cable","Glyn Mottershead"],"categories":null,"content":"","date":1520553600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1520553600,"objectID":"924a674ac01dfa2e7edfd9e659b9c6f8","permalink":"https://egrommet.github.io/publication/can-i-click-it/","publishdate":"2018-03-09T00:00:00Z","relpermalink":"/publication/can-i-click-it/","section":"publication","summary":"Does the sports media just use clickbait to generate traffic, and is this is reducing the quality of football journalism?","tags":["Sport Journalism","Data Analysis","Social Media","Journalism Studies"],"title":"'Can I click it? Yes you can': Football journalism, Twitter and clickbait","type":"publication"},{"authors":["Glyn Mottershead","Martin Chorley"],"categories":null,"content":"","date":1504306800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504306800,"objectID":"dc6b0ce608ed2e73e6745eb115fa6759","permalink":"https://egrommet.github.io/talk/gap_foj/","publishdate":"2017-09-02T00:00:00+01:00","relpermalink":"/talk/gap_foj/","section":"talk","summary":"Fake news, open data, algorithms and news room experimentation mean there's a need to train journalists beyond the basics.","tags":["Journalism Education"],"title":"Recoding journalism  education: mind the  skills gap, please!","type":"talk"},{"authors":["Glyn Mottershead"],"categories":null,"content":"","date":1499814000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1499814000,"objectID":"55e70be41ee4b6555ccc370b7430e92d","permalink":"https://egrommet.github.io/talk/visualising-on-a-deadline/","publishdate":"2017-07-12T00:00:00+01:00","relpermalink":"/talk/visualising-on-a-deadline/","section":"talk","summary":"How do you deal with statistical uncertainty when you're up against the clock?","tags":["Journalism Education","Computational Journalism","Data Journalism","Data Visualisation"],"title":"The First Commit of History: Visualising News on a Deadline","type":"talk"},{"authors":["Martin Chorley","Glyn Mottershead"],"categories":null,"content":"","date":1499295600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1499295600,"objectID":"eac104f5060d19d1aedb58c42c608331","permalink":"https://egrommet.github.io/talk/now-we-are-three/","publishdate":"2017-07-06T00:00:00+01:00","relpermalink":"/talk/now-we-are-three/","section":"talk","summary":"Key findings from the process of designing a new joint-honours Master’s degree combining Computer Science and Journalism.","tags":["Journalism Education","Computational Journalism","Data Journalism"],"title":"Now we are three: A perspective on Computational and Data Journalism Education","type":"talk"},{"authors":["Martin Chorley","Glyn Mottershead"],"categories":null,"content":"","date":1475362800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475362800,"objectID":"900514d6a949783fe95035d5f94e4e80","permalink":"https://egrommet.github.io/publication/are-you-talking-to-me/","publishdate":"2016-10-02T00:00:00+01:00","relpermalink":"/publication/are-you-talking-to-me/","section":"publication","summary":"This preliminary research aims to show how computational analysis allows us to investigate the means by which news stories are spread.","tags":["Twitter","Data Analysis","Social Media","Journalism Studies"],"title":"Are You Talking To Me?: An Analysis of Journalism Conversation on Social Media","type":"publication"},{"authors":["Tim Holmes","Glyn Mottershead"],"categories":null,"content":"","date":1440716400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1440716400,"objectID":"e4680d23b8ea482b608fd38abc270126","permalink":"https://egrommet.github.io/publication/subbing-book/","publishdate":"2015-08-28T00:00:00+01:00","relpermalink":"/publication/subbing-book/","section":"publication","summary":"Subediting and Production for Journalists is an introduction to the skills of subediting for newspapers, magazines and websites.","tags":["Subediting","Newspaper Design","Magazine Design"],"title":"Subediting and production for journalists","type":"publication"},{"authors":["Tim Holmes","Sarah Hadwin","Glyn Mottershead"],"categories":null,"content":"","date":1341097200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1341097200,"objectID":"23a5953b27b1b69ea603f790f046b6e0","permalink":"https://egrommet.github.io/publication/21st-century-journalism-handbook/","publishdate":"2012-07-01T00:00:00+01:00","relpermalink":"/publication/21st-century-journalism-handbook/","section":"publication","summary":"The 21st Century Journalism Handbook is a comprehensive guide to the core principles and practices essential to the modern journalist.","tags":["Journalism","Data Journalism","News Writing","Feature Writing","Journalism Education"],"title":"21st Century Journalism Handbook","type":"publication"},{"authors":["Terry King","Emma Duke-Williams","Glyn Mottershead"],"categories":null,"content":"","date":1249081200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1249081200,"objectID":"b26373d526fa394ae13c765109006d4e","permalink":"https://egrommet.github.io/publication/learning-and-knowledge-building/","publishdate":"2009-08-01T00:00:00+01:00","relpermalink":"/publication/learning-and-knowledge-building/","section":"publication","summary":"This paper seeks to draw together findings from a number of research studies to discuss the implications for the development of educational practices in Higher Education towards a student experience which is rich in authenticity.","tags":["Twitter","Data Analysis","Social Media","E-Learning","Education"],"title":"Learning and Knowledge Building with Web 2.0 Technologies: Implications for Teacher Education","type":"publication"}]